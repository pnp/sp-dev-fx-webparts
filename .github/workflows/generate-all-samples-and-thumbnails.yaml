name: Generate All Samples and Cache Thumbnails

on:
  push:
    branches:
      - main
    paths:
      - ".metadata/samples.json"
      - ".metadata/extensions-samples.json"
  workflow_dispatch:
  schedule:
    - cron: "0 6 * * *" # Daily 06:00 UTC
  workflow_run:
    workflows: 
      - "Merge and Distribute Samples"
      - "Sync Extensions Samples"
    types: 
      - completed
    branches:
      - main
      
jobs:
  merge_all_samples:
    runs-on: ubuntu-latest

    permissions:
      contents: write
      discussions: read

    steps:
      - name: Checkout main (source JSON)
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          ref: main
          fetch-depth: 0

      - name: Checkout Docs branch (published site output)
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          ref: Docs
          path: Docs
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Set up Node
        uses: actions/setup-node@v4
        with:
          node-version: "20"

      - name: Merge + slim samples files
        id: merge
        run: |
          python3 << 'EOF'
          import json
          import sys
          from pathlib import Path

          def flatten_samples(data):
              if isinstance(data, list):
                  out = []
                  for item in data:
                      if isinstance(item, dict):
                          out.append(item)
                      elif isinstance(item, list):
                          out.extend(flatten_samples(item))
                  return out
              if isinstance(data, dict):
                  return [data]
              return []

          def pick_primary_thumbnail(sample: dict):
              thumbs = sample.get("thumbnails") or []
              if not isinstance(thumbs, list):
                  return None

              images = [t for t in thumbs if isinstance(t, dict) and t.get("type") == "image" and t.get("url")]
              if not images:
                  return None

              def order_key(t):
                  o = t.get("order")
                  return o if isinstance(o, int) else 999999

              images.sort(key=order_key)
              return images[0]

          def slim_sample(sample: dict):
              primary = pick_primary_thumbnail(sample)

              out = {
                  "name": sample.get("name"),
                  "source": sample.get("source"),
                  "title": sample.get("title"),
                  "shortDescription": sample.get("shortDescription"),
                  "url": sample.get("url"),
                  "downloadUrl": sample.get("downloadUrl"),
                  "updateDateTime": sample.get("updateDateTime"),
                  "metadata": sample.get("metadata") or [],
                  "tags": sample.get("tags") or [],
                  "categories": sample.get("categories") or [],
                  "authors": sample.get("authors") or [],
                  "thumbnails":  [primary] if primary else [],
              }
              return out

          all_samples = []
          errors = []
          file_stats = {}

          base_path = Path.cwd().resolve()
          metadata_dir = base_path / ".metadata"
          metadata_dir.mkdir(parents=True, exist_ok=True)

          files_to_merge = [
              ("samples.json", "WebParts"),
              ("extensions-samples.json", "Extensions")
          ]

          print("ðŸ”„ Merging + slimming sample files...\n")

          for filename, source_type in files_to_merge:
              file_path = metadata_dir / filename
              if not file_path.exists():
                  print(f"â„¹ï¸ {filename}: File not found (skipping)")
                  file_stats[filename] = {"type": source_type, "count": 0, "status": "not_found"}
                  continue

              try:
                  content = file_path.read_text(encoding="utf-8").strip()
                  if not content:
                      errors.append({"file": filename, "error": "Empty file"})
                      print(f"âœ— {filename}: Empty file")
                      file_stats[filename] = {"type": source_type, "count": 0, "status": "empty"}
                      continue

                  data = json.loads(content)
                  samples = flatten_samples(data)
                  if not samples:
                      errors.append({"file": filename, "error": "No valid samples found after flattening"})
                      print(f"âœ— {filename}: No valid samples found")
                      file_stats[filename] = {"type": source_type, "count": 0, "status": "no_samples"}
                      continue

                  slimmed = [slim_sample(s) for s in samples if isinstance(s, dict)]
                  all_samples.extend(slimmed)
                  print(f"âœ“ {filename}: Added {len(slimmed)} {source_type} samples")
                  file_stats[filename] = {"type": source_type, "count": len(slimmed), "status": "success"}

              except json.JSONDecodeError as e:
                  errors.append({"file": filename, "error": f"JSON decode error: {str(e)}"})
                  print(f"âœ— {filename}: JSON error - {str(e)}")
                  file_stats[filename] = {"type": source_type, "count": 0, "status": "json_error"}
              except Exception as e:
                  errors.append({"file": filename, "error": f"Unexpected error: {str(e)}"})
                  print(f"âœ— {filename}: Error - {str(e)}")
                  file_stats[filename] = {"type":  source_type, "count": 0, "status": "error"}

          out_path = metadata_dir / "all-samples.json"
          try:
              out_path.write_text(json.dumps(all_samples, indent=2, ensure_ascii=False), encoding="utf-8")
              print(f"\nâœ“ Successfully wrote {out_path}")
          except Exception as e:
              print(f"\nâœ— Error writing {out_path}: {str(e)}")
              sys.exit(1)

          merge_errors_file = metadata_dir / "merge-errors.json"
          if errors:
              payload = {
                  "timestamp": "${{ github.event.head_commit.timestamp }}",
                  "commit": "${{ github.sha }}",
                  "errors": errors
              }
              merge_errors_file.write_text(json.dumps(payload, indent=2, ensure_ascii=False), encoding="utf-8")
              print(f"âš ï¸ Errors written to: {merge_errors_file}")
              has_errors = "true"
          else:
              if merge_errors_file.exists():
                  merge_errors_file.unlink()
                  print("âœ“ No errors.  Removed existing merge-errors.json")
              has_errors = "false"

          import os
          with open(os.environ["GITHUB_OUTPUT"], "a") as f:
              f.write(f"has_errors={has_errors}\n")
              f.write(f"total_samples={len(all_samples)}\n")
              f.write(f"file_stats={json.dumps(file_stats)}\n")
          EOF

      - name: Generate thumbnails
        id: thumbs
        uses: ./.github/actions/generate-thumbnails
        with:
          docs-path: Docs
          all-samples-path: .metadata/all-samples.json
          allow-remote: "true"
          node-version: "20"
          install-deps: "true"

      - name: Generate avatars
        id: avatars
        uses: ./.github/actions/generate-avatars
        with:
          docs-path: Docs
          all-samples-path: .metadata/all-samples.json
          allow-remote: "true"
          node-version: "20"
          install-deps: "true"

      - name: Tally discussion reactions
        id: reactions
        uses: ./.github/actions/tally-reactions

      - name: Save likes.json into Docs/docs/data
        shell: bash
        run: |
          mkdir -p Docs/docs/data
          echo '${{ steps.reactions.outputs.result }}' > Docs/docs/data/likes.json

          # Validate JSON (fail fast if the action output got truncated)
          jq empty Docs/docs/data/likes.json


      - name: Write published JSON files into Docs/docs/data
        id: publish_json
        run: |
          node << 'EOF'
          const fs = require("fs");
          const path = require("path");

          const allSamplesPath = path.resolve(".metadata/all-samples.json");
          const samples = JSON.parse(fs.readFileSync(allSamplesPath, "utf8"));

          // ----- Merge reactions from Docs/docs/data/likes.json into each sample -----
          const likesPath = path.resolve("Docs/docs/data/likes.json");
          let likes = null;

          if (fs.existsSync(likesPath)) {
            likes = JSON.parse(fs.readFileSync(likesPath, "utf8"));
          }

          const discussions = likes?.discussions && typeof likes.discussions === "object"
            ? likes.discussions
            : {};

          for (const s of samples) {
            const key = `sample:${s.name}`;   // join key matches tally action title convention
            const d = discussions[key];

            if (d) {
              s.reactions = {
                total: d.totalReactions ?? 0,
                counts: d.reactionCounts ?? {},
                url: d.url ?? ""
                // reactors: d.allReactors ?? []   // optional; include only if you need it on the site
              };
            } else {
              s.reactions = { total: 0, counts: {}, url: "" };
            }
          }

          const dataDir = path.resolve("Docs/docs/data");
          fs.mkdirSync(dataDir, { recursive: true });

          // all-samples.json
          fs.writeFileSync(
            path.join(dataDir, "all-samples.json"),
            JSON.stringify(samples, null, 2),
            "utf8"
          );

          // authors.json (deduped)
          const byKey = new Map();
          for (const s of samples) {
            const authors = Array.isArray(s.authors) ? s.authors : [];
            for (const a of authors) {
              if (!a) continue;

                           const key =
                (a.gitHubAccount && `gh:${a.gitHubAccount.toLowerCase()}`) ||
                (a.avatarSourceUrl && `src:${a.avatarSourceUrl}`) ||
                (a.pictureUrl && `pic:${a.pictureUrl}`) ||
                (a.name && `name:${a.name.toLowerCase()}`);

              if (!key) continue;

              const existing = byKey.get(key) || {};
              byKey.set(key, {
                gitHubAccount: a.gitHubAccount || existing.gitHubAccount || "",
                name: a.name || existing.name || "",
                pictureUrl: a.pictureUrl || existing.pictureUrl || "",
                avatarSourceUrl: a.avatarSourceUrl || existing.avatarSourceUrl || ""
              });
            }
          }

          const authors = Array.from(byKey.values())
            .sort((x, y) => (x.name || "").localeCompare(y.name || ""));

          fs.writeFileSync(
            path.join(dataDir, "authors.json"),
            JSON.stringify(authors, null, 2),
            "utf8"
          );

          // optional tiny meta file (handy for debugging)
          fs.writeFileSync(
            path.join(dataDir, "generated-meta.json"),
            JSON.stringify({ generatedAt: new Date().toISOString(), sampleCount: samples.length }, null, 2),
            "utf8"
          );
          EOF

      - name: Check Docs working tree changes
        id: check_changes
        shell: bash
        run: |
          cd Docs
          if [ -n "$(git status --porcelain)" ]; then
            echo "changes=true" >> "$GITHUB_OUTPUT"
          else
            echo "changes=false" >> "$GITHUB_OUTPUT"
          fi


      - name: Commit + push to Docs branch only
        shell: bash
        run: |
          cd Docs
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"

          git add -A docs/images/thumbnails docs/images/avatars docs/data

          if git diff --cached --exit-code; then
            echo "â„¹ï¸ No changes to publish to Docs branch"
            exit 0
          fi

          git commit -m "chore: publish samples data + images [skip ci]"
          git push origin HEAD:Docs
          echo "âœ… Changes committed and pushed"

      - name: Generate workflow summary
        if: always()
        shell: bash
        run: |
          {
            echo "# ðŸ“Š Merge All Samples Workflow Summary"
            echo
            echo "## Workflow Details"
            echo "- **Triggered by**: ${{ github.event_name }}"
            echo "- **Run number**: ${{ github.run_number }}"
            echo "- **Commit**: ${{ github.sha }}"
            echo "- **Branch**: ${{ github.ref_name }}"
            echo
            echo "## ðŸ“¦ Sample Processing"
            echo "| Metric | Value |"
            echo "|--------|-------|"
            echo "| **Total Samples** | ${{ steps.merge.outputs.total_samples }} |"
            echo "| **Merge Errors** | ${{ steps.merge.outputs.has_errors == 'true' && 'âš ï¸ Yes' || 'âœ… No' }} |"
            echo
            echo "## ðŸ–¼ï¸ Thumbnails"
            echo "| Metric | Count |"
            echo "|--------|-------|"
            echo "| **Generated/updated** | ${{ steps.thumbs.outputs.thumbnails_generated }} |"
            echo "| **Failed** | ${{ steps.thumbs.outputs.thumbnails_failed }} |"
            echo "| **Samples with thumbnail URL set** | ${{ steps.thumbs.outputs.samples_with_thumbnails }} |"
            echo
            echo "## ðŸ§‘â€ðŸŽ¨ Avatars"
            echo "| Metric | Count |"
            echo "|--------|-------|"
            echo "| **Generated/updated** | ${{ steps.avatars.outputs.avatars_generated }} |"
            echo "| **Updated** | ${{ steps.avatars.outputs.authors_updated }} |"
            echo "| **Skipped** | ${{ steps.avatars.outputs.avatars_skipped }} |"
            echo "| **Deleted (orphans)** | ${{ steps.avatars.outputs.avatars_deleted }} |"
            echo

            echo "## ðŸ‘ Reactions"
            echo "| Metric | Count |"
            echo "|--------|-------|"
            echo "| **Matched discussions** | ${{ steps.reactions.outputs.matched_discussions }} |"
            echo "| **Total reactions** | ${{ steps.reactions.outputs.total_reactions }} |"
            echo
            echo "## ðŸ“ Git Changes"
            echo "| Status | Result |"
            echo "|--------|--------|"
            echo "| **Changes Detected** | ${{ steps.check_changes.outputs.changes == 'true' && 'âœ… Yes' || 'â„¹ï¸ No' }} |"
          } >> "$GITHUB_STEP_SUMMARY"
