name: Generate author avatars
description: Normalize author avatars + rewrite all-samples.json authors.pictureUrl (publish to Docs branch)

inputs:
  node-version:
    required: false
    default: "20"
  docs-path:
    required: false
    default: "Docs"
  all-samples-path:
    required: false
    default: ".metadata/all-samples.json"
  install-deps:
    required: false
    default: "true"
  allow-remote:
    required: false
    default: "true"

outputs:
  avatars_generated:
    description: Number of avatar files generated/updated
    value: ${{ steps.metrics.outputs.avatars_generated }}
  authors_updated:
    description: Number of author entries whose pictureUrl was set/rewritten
    value: ${{ steps.metrics.outputs.authors_updated }}
  avatars_skipped:
    description: Number skipped (missing/unsupported)
    value: ${{ steps.metrics.outputs.avatars_skipped }}
  avatars_deleted:
    description: Number of avatar images deleted as orphans
    value: ${{ steps.metrics.outputs.avatars_deleted }}

runs:
  using: composite
  steps:
    - name: Set up Node
      uses: actions/setup-node@v4
      with:
        node-version: ${{ inputs.node-version }}

    - name: Install avatar deps
      if: ${{ inputs.install-deps == 'true' }}
      shell: bash
      run: |
        npm init -y >/dev/null 2>&1
        npm install sharp >/dev/null 2>&1

    - id: metrics
      name: Normalize author avatars + rewrite all-samples.json authors.pictureUrl (publish to Docs branch)
      shell: bash
      run: |
        node << 'EOF'
        const fs = require("fs");
        const path = require("path");
        const sharp = require("sharp");

        const docsPath = process.env.DOCS_PATH || "Docs";
        const allSamplesPath = path.resolve(process.env.ALL_SAMPLES_PATH || ".metadata/all-samples.json");

        const repo = process.env.GITHUB_REPOSITORY;
        const repoName = repo.split("/")[1];
        const pagesBase = `/${repoName}/`;
        const avatarUrlBase = `${pagesBase}images/avatars/`;

        const samples = JSON.parse(fs.readFileSync(allSamplesPath, "utf8"));

        const avatarsDir = path.resolve(docsPath, "docs/images/avatars");
        fs.mkdirSync(avatarsDir, { recursive: true });

        let avatarsGenerated = 0;
        let avatarsUpdated = 0;
        let avatarsFailed = 0;
        let avatarsSkipped = 0;
        let avatarsDeleted = 0;

        // Track which files should exist after generation
        const expectedFiles = new Set(["manifest.json", ".gitkeep"]); 

        function safeFileName(name) {
          return String(name).replace(/[^a-zA-Z0-9._-]/g, "_");
        }

        function getAllAuthors(sample) {
          if (Array.isArray(sample.authors)) return sample.authors;
          if (sample.author) return [sample.author];
          return [];
        }

        const crypto = require("crypto");

        const allowRemote = String(process.env.ALLOW_REMOTE || "true").toLowerCase() === "true";

        const manifestPath = path.join(avatarsDir, "manifest.json");
        const oldManifest = fs.existsSync(manifestPath)
          ? JSON.parse(fs.readFileSync(manifestPath, "utf8"))
          : {}; // keyed by sourceUrl

        function safeSlug(s) {
          return String(s || "author")
            .trim()
            .toLowerCase()
            .replace(/[^a-z0-9]+/g, "-")
            .replace(/^-+|-+$/g, "")
            .slice(0, 40) || "author";
        }

        function sha256Hex(buf) {
          return crypto.createHash("sha256").update(buf).digest("hex");
        }

        async function fetchBuffer(url) {
          const res = await fetch(url, { redirect: "follow" });
          if (!res.ok) throw new Error(`HTTP ${res.status}`);
          const ab = await res.arrayBuffer();
          return {
            buf: Buffer.from(ab),
            contentType: res.headers.get("content-type") || ""
          };
        }

        async function normalizeRemoteToWebp(inputBuf, contentType, sizePx) {
          const isSvg = /image\/svg\+xml/i.test(contentType);
          const img = isSvg
            ? sharp(inputBuf, { density: 256 })
            : sharp(inputBuf, { animated: true, pages: 1 });

          return await img
            .resize(sizePx, sizePx, { fit: "cover", position: "centre" })
            .webp({ quality: 80, effort: 4 })
            .toBuffer();
        }

        async function normalizeAvatar(url, slugBase) {
          if (!url || typeof url !== "string") {
            avatarsSkipped += 1;
            return null;
          }

          // Remote URL path (the common case)
          if (url.startsWith("http://") || url.startsWith("https://")) {
            if (!allowRemote) {
              avatarsSkipped += 1;
              return null;
            }

            // Manifest cache hit?
            const prev = oldManifest[url];
            if (prev?.file) {
              const prevPath = path.join(avatarsDir, prev.file);
              if (fs.existsSync(prevPath)) {
                expectedFiles.add("manifest.json");
                expectedFiles.add(prev.file);
                avatarsSkipped += 1;
                return { outFile: prev.file, sourceUrl: url, cached: true };
              }
            }

            // Download + normalize + hashed filename
            const sizePx = 28;
            const { buf, contentType } = await fetchBuffer(url);
            const outBuf = await normalizeRemoteToWebp(buf, contentType, sizePx);

            const hash = sha256Hex(outBuf).slice(0, 12);
            const slug = safeSlug(slugBase);
            const outFile = `${slug}.${hash}.webp`;
            const outPath = path.join(avatarsDir, outFile);

            if (!fs.existsSync(outPath)) fs.writeFileSync(outPath, outBuf);

            // Update manifest entry (keyed by sourceUrl)
            oldManifest[url] = { sourceUrl: url, file: outFile, sizePx, sha256_12: hash };

            expectedFiles.add("manifest.json");
            expectedFiles.add(outFile);
            avatarsGenerated += 1;
            return { outFile, sourceUrl: url, cached: false };
          }

          // Local file path fallback (keep your current behavior if you still need it)
          const inputPath = path.resolve(url);
          if (!fs.existsSync(inputPath)) {
            avatarsSkipped += 1;
            return null;
          }

          const base = safeFileName(path.basename(inputPath, path.extname(inputPath)));
          const outFile = `${base}.webp`;
          const outPath = path.join(avatarsDir, outFile);

          expectedFiles.add(outFile);

          const alreadyExisted = fs.existsSync(outPath);
          if (!alreadyExisted) {
            await sharp(inputPath)
              .resize({ width: 28, height: 28, fit: "cover" })
              .webp({ quality: 82 })
              .toFile(outPath);
            avatarsGenerated += 1;
          }

          return { outFile, sourceUrl: null, cached: alreadyExisted };
        }


        (async () => {
          for (const s of samples) {
            const authors = getAllAuthors(s);
            if (!authors.length) continue;

            for (const a of authors) {
              if (!a) continue;

              // Exact old behavior: only remote pictureUrl
              const sourceUrl = a.pictureUrl;
              if (!sourceUrl || typeof sourceUrl !== "string") continue;
              if (!sourceUrl.startsWith("http://") && !sourceUrl.startsWith("https://")) continue;

              const slugBase = a.gitHubAccount || a.name || "author";

              try {
                const result = await normalizeAvatar(sourceUrl, slugBase);
                if (!result?.outFile) continue;

                // Preserve original remote URL like the old workflow
                if (result.sourceUrl && !a.avatarSourceUrl) {
                  a.avatarSourceUrl = result.sourceUrl;
                }

                a.pictureUrl = `${avatarUrlBase}${encodeURIComponent(result.outFile)}`;
                avatarsUpdated += 1;
              } catch (err) {
                avatarsFailed += 1;
                console.warn(
                  `[avatars] Failed for ${a.gitHubAccount || a.name || "author"} (${sourceUrl}):`,
                  err?.message ?? err
                );
                continue;
              }
            }
          }

          // Persist JSON
          fs.writeFileSync(allSamplesPath, JSON.stringify(samples, null, 2) + "\n");

          // Delete orphans
          if (fs.existsSync(avatarsDir)) {
            for (const f of fs.readdirSync(avatarsDir)) {
              const full = path.join(avatarsDir, f);
              if (!fs.statSync(full).isFile()) continue;

              if (!expectedFiles.has(f)) {
                fs.unlinkSync(full);
                avatarsDeleted += 1;
              }
            }
          }

          // Persist manifest
          fs.writeFileSync(manifestPath, JSON.stringify(oldManifest, null, 2) + "\n", "utf8");

          // Outputs (single source of truth)
          const outPath = process.env.GITHUB_OUTPUT;
          fs.appendFileSync(outPath, `avatars_generated=${avatarsGenerated}\n`);
          fs.appendFileSync(outPath, `authors_updated=${avatarsUpdated}\n`);
          fs.appendFileSync(outPath, `avatars_skipped=${avatarsSkipped}\n`);
          fs.appendFileSync(outPath, `avatars_deleted=${avatarsDeleted}\n`);
          fs.appendFileSync(outPath, `avatars_failed=${avatarsFailed}\n`);

          // Step summary
          const summaryPath = process.env.GITHUB_STEP_SUMMARY;
          const lines = [];
          lines.push(`## Avatars`);
          lines.push(`- Avatars generated/updated: **${avatarsGenerated}**`);
          lines.push(`- Author entries updated: **${avatarsUpdated}**`);
          lines.push(`- Skipped: **${avatarsSkipped}**`);
          lines.push(`- Failed: **${avatarsFailed}**`);
          lines.push(`- Deleted (orphans): **${avatarsDeleted}**`);
          fs.appendFileSync(summaryPath, lines.join("\n") + "\n");
        })().catch(err => {
          console.error(err);
          process.exit(1);
        });

        EOF
      env:
        DOCS_PATH: ${{ inputs.docs-path }}
        ALL_SAMPLES_PATH: ${{ inputs.all-samples-path }}
        ALLOW_REMOTE: ${{ inputs.allow-remote }}

