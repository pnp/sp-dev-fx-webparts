name: Generate All Samples and Cache Thumbnails

on:
  push:
    branches:
      - main
    paths:
      - ".metadata/samples.json"
      - ".metadata/extensions-samples.json"
  workflow_dispatch:
  schedule:
    - cron: "0 6 * * *" # Daily 06:00 UTC
  workflow_run:
    workflows: 
      - "Merge and Distribute Samples"
      - "Sync Extensions Samples"
    types: 
      - completed
    branches:
      - main
      
jobs:
  merge_all_samples:
    runs-on: ubuntu-latest

    permissions:
      contents: write

    steps:
      - name: Checkout main (source JSON)
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          ref: main
          fetch-depth: 0

      - name: Checkout Docs branch (published site output)
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          ref: Docs
          path: Docs
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Set up Node
        uses: actions/setup-node@v4
        with:
          node-version: "20"

      - name: Merge + slim samples files
        id: merge
        run: |
          python3 << 'EOF'
          import json
          import sys
          from pathlib import Path

          def flatten_samples(data):
              if isinstance(data, list):
                  out = []
                  for item in data:
                      if isinstance(item, dict):
                          out.append(item)
                      elif isinstance(item, list):
                          out.extend(flatten_samples(item))
                  return out
              if isinstance(data, dict):
                  return [data]
              return []

          def pick_primary_thumbnail(sample: dict):
              thumbs = sample.get("thumbnails") or []
              if not isinstance(thumbs, list):
                  return None

              images = [t for t in thumbs if isinstance(t, dict) and t.get("type") == "image" and t.get("url")]
              if not images:
                  return None

              def order_key(t):
                  o = t.get("order")
                  return o if isinstance(o, int) else 999999

              images.sort(key=order_key)
              return images[0]

          def slim_sample(sample: dict):
              primary = pick_primary_thumbnail(sample)

              out = {
                  "name": sample.get("name"),
                  "source": sample.get("source"),
                  "title": sample.get("title"),
                  "shortDescription": sample.get("shortDescription"),
                  "url": sample.get("url"),
                  "downloadUrl": sample.get("downloadUrl"),
                  "updateDateTime": sample.get("updateDateTime"),
                  "metadata": sample.get("metadata") or [],
                  "tags": sample.get("tags") or [],
                  "categories": sample.get("categories") or [],
                  "authors": sample.get("authors") or [],
                  "thumbnails":  [primary] if primary else [],
              }
              return out

          all_samples = []
          errors = []
          file_stats = {}

          base_path = Path.cwd().resolve()
          metadata_dir = base_path / ".metadata"
          metadata_dir.mkdir(parents=True, exist_ok=True)

          files_to_merge = [
              ("samples.json", "WebParts"),
              ("extensions-samples.json", "Extensions")
          ]

          print("üîÑ Merging + slimming sample files...\n")

          for filename, source_type in files_to_merge:
              file_path = metadata_dir / filename
              if not file_path.exists():
                  print(f"‚ÑπÔ∏è {filename}: File not found (skipping)")
                  file_stats[filename] = {"type": source_type, "count": 0, "status": "not_found"}
                  continue

              try:
                  content = file_path.read_text(encoding="utf-8").strip()
                  if not content:
                      errors.append({"file": filename, "error": "Empty file"})
                      print(f"‚úó {filename}: Empty file")
                      file_stats[filename] = {"type": source_type, "count": 0, "status": "empty"}
                      continue

                  data = json.loads(content)
                  samples = flatten_samples(data)
                  if not samples:
                      errors.append({"file": filename, "error": "No valid samples found after flattening"})
                      print(f"‚úó {filename}: No valid samples found")
                      file_stats[filename] = {"type": source_type, "count": 0, "status": "no_samples"}
                      continue

                  slimmed = [slim_sample(s) for s in samples if isinstance(s, dict)]
                  all_samples.extend(slimmed)
                  print(f"‚úì {filename}: Added {len(slimmed)} {source_type} samples")
                  file_stats[filename] = {"type": source_type, "count": len(slimmed), "status": "success"}

              except json.JSONDecodeError as e:
                  errors.append({"file": filename, "error": f"JSON decode error: {str(e)}"})
                  print(f"‚úó {filename}: JSON error - {str(e)}")
                  file_stats[filename] = {"type": source_type, "count": 0, "status": "json_error"}
              except Exception as e:
                  errors.append({"file": filename, "error": f"Unexpected error: {str(e)}"})
                  print(f"‚úó {filename}: Error - {str(e)}")
                  file_stats[filename] = {"type":  source_type, "count": 0, "status": "error"}

          out_path = metadata_dir / "all-samples.json"
          try:
              out_path.write_text(json.dumps(all_samples, indent=2, ensure_ascii=False), encoding="utf-8")
              print(f"\n‚úì Successfully wrote {out_path}")
          except Exception as e:
              print(f"\n‚úó Error writing {out_path}: {str(e)}")
              sys.exit(1)

          merge_errors_file = metadata_dir / "merge-errors.json"
          if errors:
              payload = {
                  "timestamp": "${{ github.event.head_commit.timestamp }}",
                  "commit": "${{ github.sha }}",
                  "errors": errors
              }
              merge_errors_file.write_text(json.dumps(payload, indent=2, ensure_ascii=False), encoding="utf-8")
              print(f"‚ö†Ô∏è Errors written to: {merge_errors_file}")
              has_errors = "true"
          else:
              if merge_errors_file.exists():
                  merge_errors_file.unlink()
                  print("‚úì No errors.  Removed existing merge-errors.json")
              has_errors = "false"

          import os
          with open(os.environ["GITHUB_OUTPUT"], "a") as f:
              f.write(f"has_errors={has_errors}\n")
              f.write(f"total_samples={len(all_samples)}\n")
              f.write(f"file_stats={json.dumps(file_stats)}\n")
          EOF

      - name: Generate thumbnails
        uses: ./.github/actions/generate-thumbnails
        with:
          docs-path: Docs
          all-samples-path: .metadata/all-samples.json
          node-version: "20"
          install-deps: "true"

      - name: Generate avatars
        uses: ./.github/actions/generate-avatars
        with:
          docs-path: Docs
          all-samples-path: .metadata/all-samples.json
          node-version: "20"
          install-deps: "true"

      - name: Write published JSON files into Docs/docs/data
        id: publish_json
        run: |
          node << 'EOF'
          const fs = require("fs");
          const path = require("path");

          const allSamplesPath = path.resolve(".metadata/all-samples.json");
          const samples = JSON.parse(fs.readFileSync(allSamplesPath, "utf8"));

          const dataDir = path.resolve("Docs/docs/data");
          fs.mkdirSync(dataDir, { recursive: true });

          // all-samples.json
          fs.writeFileSync(
            path.join(dataDir, "all-samples.json"),
            JSON.stringify(samples, null, 2),
            "utf8"
          );

          // authors.json (deduped)
          const byKey = new Map();
          for (const s of samples) {
            const authors = Array.isArray(s.authors) ? s.authors : [];
            for (const a of authors) {
              if (!a) continue;
              const key =
                (a.gitHubAccount && `gh:${a.gitHubAccount.toLowerCase()}`) ||
                (a.avatarSourceUrl && `src:${a.avatarSourceUrl}`) ||
                (a.pictureUrl && `pic:${a.pictureUrl}`) ||
                (a.name && `name:${a.name.toLowerCase()}`);

              if (!key) continue;

              const existing = byKey.get(key) || {};
              byKey.set(key, {
                gitHubAccount: a.gitHubAccount || existing.gitHubAccount || "",
                name: a.name || existing.name || "",
                company: a.company || existing.company || "",
                pictureUrl: a.pictureUrl || existing.pictureUrl || "",
                avatarSourceUrl: a.avatarSourceUrl || existing.avatarSourceUrl || ""
              });
            }
          }

          const authors = Array.from(byKey.values())
            .sort((x, y) => (x.name || "").localeCompare(y.name || ""));

          fs.writeFileSync(
            path.join(dataDir, "authors.json"),
            JSON.stringify(authors, null, 2),
            "utf8"
          );

          // optional tiny meta file (handy for debugging)
          fs.writeFileSync(
            path.join(dataDir, "generated-meta.json"),
            JSON.stringify({ generatedAt: new Date().toISOString(), sampleCount: samples.length }, null, 2),
            "utf8"
          );
          EOF

      - name: Commit + push to Docs branch only
        run: |
          cd Docs
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"

          git add docs/images/avatars docs/images/thumbnails docs/data/all-samples.json docs/data/authors.json docs/data/generated-meta.json

          if git diff --cached --exit-code; then
            echo "‚ÑπÔ∏è No changes to publish to Docs branch"
            exit 0
          fi

          git commit -m "chore: publish samples data + images [skip ci]"
          git push
          echo "‚úÖ Changes committed and pushed"

      - name: Generate workflow summary
        if: always()
        run: |
          cat << 'EOF' >> $GITHUB_STEP_SUMMARY
          # üìä Merge All Samples Workflow Summary
          
          ## Workflow Details
          - **Triggered by**: ${{ github.event_name }}
          - **Run number**: ${{ github.run_number }}
          - **Commit**:  ${{ github.sha }}
          - **Branch**: ${{ github.ref_name }}
          
          ## üì¶ Sample Processing
          
          | Metric | Value |
          |--------|-------|
          | **Total Samples** | ${{ steps.merge.outputs.total_samples }} |
          | **Merge Errors** | ${{ steps.merge.outputs.has_errors == 'true' && '‚ö†Ô∏è Yes' || '‚úÖ No' }} |
          
          ## üßë‚Äçüé® Avatar Normalization

          | Metric | Count |
          |--------|-------|
          | **Processed** | ${{ steps.avatars.outputs.avatars_processed }} |
          | **Skipped (cached)** | ${{ steps.avatars.outputs.avatars_skipped }} |
          | **Failed** | ${{ steps.avatars.outputs.avatars_failed }} |
          | **Deleted (orphaned)** | ${{ steps.avatars.outputs.avatars_deleted }} |

          ### Source Files
          EOF

          # Parse and display file stats
          python3 << 'PYEOF'
          import json
          import os

          file_stats_json = """${{ steps.merge.outputs.file_stats }}"""
          
          if file_stats_json:
              try:
                  file_stats = json.loads(file_stats_json)
                  
                  with open(os.environ["GITHUB_STEP_SUMMARY"], "a") as f:
                      for filename, stats in file_stats.items():
                          status_emoji = {
                              "success": "‚úÖ",
                              "not_found": "‚ÑπÔ∏è",
                              "empty": "‚ö†Ô∏è",
                              "no_samples": "‚ö†Ô∏è",
                              "json_error": "‚ùå",
                              "error": "‚ùå"
                          }.get(stats.get("status"), "‚ùì")
                          
                          f.write(f"- {status_emoji} **{filename}** ({stats.get('type')}): {stats.get('count')} samples\n")
              except: 
                  pass
          PYEOF

          cat << 'EOF' >> $GITHUB_STEP_SUMMARY
          
          ## üñºÔ∏è Thumbnail Optimization
          
          | Metric | Count |
          |--------|-------|
          | **Processed** | ${{ steps.thumbs.outputs.thumbs_processed }} |
          | **Skipped (cached)** | ${{ steps.thumbs.outputs.thumbs_skipped }} |
          | **Failed** | ${{ steps.thumbs.outputs.thumbs_failed }} |
          | **Deleted (orphaned)** | ${{ steps.thumbs.outputs.thumbs_deleted }} |
          
          EOF
          
          if [ "${{ steps.thumbs.outputs.has_thumb_failures }}" == "true" ]; then
            echo "### ‚ö†Ô∏è Failed Thumbnails" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "The following thumbnails failed to process and are using original URLs.  See \`.metadata/thumbnail-failures.json\` for details:" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            
            if [ -f .metadata/thumbnail-failures.json ]; then
              python3 << 'PYEOF'
          import json
          import os
          
          with open(".metadata/thumbnail-failures.json") as f:
              failures = json.load(f)
          
          with open(os.environ["GITHUB_STEP_SUMMARY"], "a") as summary:
              summary.write("| Sample | Error |\n")
              summary.write("|--------|-------|\n")
              for failure in failures:
                  summary.write(f"| {failure['name']} | {failure['error']} |\n")
          PYEOF
            fi
          fi
          
          cat << 'EOF' >> $GITHUB_STEP_SUMMARY
          
          ## üìù Git Changes
          
          | Status | Result |
          |--------|--------|
          | **Changes Detected** | ${{ steps.check_changes.outputs.changes == 'true' && '‚úÖ Yes' || '‚ÑπÔ∏è No' }} |
          | **Committed & Pushed** | ${{ steps.check_changes.outputs.changes == 'true' && '‚úÖ Yes' || '‚ÑπÔ∏è No changes to commit' }} |
          
          ---
          
          ${{ steps.merge.outputs.has_errors == 'true' && '‚ö†Ô∏è **Warning**:  Merge completed with errors.  Check `.metadata/merge-errors.json` for details.' || '‚úÖ **Success**: All samples merged successfully!' }}
          EOF